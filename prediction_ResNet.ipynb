{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-24T13:16:26.052793Z","iopub.status.busy":"2024-03-24T13:16:26.052221Z","iopub.status.idle":"2024-03-24T13:16:51.406674Z","shell.execute_reply":"2024-03-24T13:16:51.40502Z","shell.execute_reply.started":"2024-03-24T13:16:26.052727Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Data Visualization \u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import cv2\n","import os\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","# Data Visualization \n","import plotly.express as px\n","import random\n","from tensorflow.keras import layers, Model\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Organization\n","The study employs a comprehensive dataset consisting of images of skin lesions, specifically focusing on identifying monkeypox infections. The dataset is meticulously organized into three distinct sets to facilitate the training, validation, and evaluation phases of the machine learning model. Each set is stored in a separate directory, ensuring a streamlined process for model development and testing. The directory paths for these datasets are as follows:\n","\n","Training Set: The training set, essential for the initial training of the neural network, is located at /monkeypox-skin-lesion-dataset/Fold1/Fold1/Fold1/Train/. This dataset comprises a diverse collection of lesion images used to teach the model the characteristics of monkeypox infections.\n","\n","Validation Set: The validation set, used to tune the model's hyperparameters and prevent overfitting, is found at /monkeypox-skin-lesion-dataset/Fold1/Fold1/Fold1/Val/. Periodic evaluation of the model on this dataset during training allows for adjustments before final testing, ensuring the model generalizes well to new data.\n","\n","Test Set: The test set, crucial for evaluating the model's performance on unseen data, is stored at /monkeypox-skin-lesion-dataset/Fold1/Fold1/Fold1/Test/. This final evaluation provides an unbiased assessment of the model's ability to classify new images accurately, reflecting its potential effectiveness in real-world applications.\n","\n","The division of the dataset into training, validation, and testing sets is a standard practice in machine learning and deep learning projects. It ensures that the model can learn from a variety of examples, adjust to prevent overfitting, and finally, be tested to provide an accurate measure of its performance. This structured approach to dataset organization is crucial for developing robust and reliable predictive models."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:51.411183Z","iopub.status.busy":"2024-03-24T13:16:51.40929Z","iopub.status.idle":"2024-03-24T13:16:51.416675Z","shell.execute_reply":"2024-03-24T13:16:51.415565Z","shell.execute_reply.started":"2024-03-24T13:16:51.411134Z"},"trusted":true},"outputs":[],"source":["train_dir = \"D:/project_monkey/Project_Monkey/monkeypox-skin-lesion-dataset/Fold1/Fold1/Fold1/Train\"\n","val_dir = \"D:/project_monkey/Project_Monkey/monkeypox-skin-lesion-dataset/Fold1/Fold1/Fold1/Val\"\n","test_dir = \"D:/project_monkey/Project_Monkey/monkeypox-skin-lesion-dataset/Fold1/Fold1/Fold1/Test\""]},{"cell_type":"markdown","metadata":{},"source":["# Data Description and Preliminary Exploration\n","\n","To facilitate a comprehensive analysis of the monkeypox skin lesion dataset, the study leverages a metadata file that contains detailed information about each image within the dataset. This metadata file, named Monkeypox_Dataset_metadata.csv, is pivotal for understanding the characteristics and annotations of the images. The acquisition of this metadata is accomplished through the utilization of the Pandas library, a powerful data manipulation tool in Python, which provides efficient and straightforward methods for handling structured data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:51.420315Z","iopub.status.busy":"2024-03-24T13:16:51.419471Z","iopub.status.idle":"2024-03-24T13:16:51.529322Z","shell.execute_reply":"2024-03-24T13:16:51.528031Z","shell.execute_reply.started":"2024-03-24T13:16:51.420268Z"},"trusted":true},"outputs":[],"source":["info_file = 'D:/project_monkey/Project_Monkey/monkeypox-skin-lesion-dataset/Monkeypox_Dataset_metadata.csv'\n","info = pd.read_csv(info_file)\n","info.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation\n","\n","Image Dataset Construction\n","To develop and evaluate the machine learning model for classifying skin lesions as indicative of monkeypox or not, the study employed high-resolution images from a structured dataset. The images were organized into separate directories for training, validation, and testing, facilitating a streamlined workflow for model development and evaluation. A crucial step in preparing these images for input into the neural network involved resizing and batching the images, operations that were performed using TensorFlow, a comprehensive open-source platform for machine learning."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:51.534033Z","iopub.status.busy":"2024-03-24T13:16:51.532612Z","iopub.status.idle":"2024-03-24T13:16:52.614319Z","shell.execute_reply":"2024-03-24T13:16:52.613113Z","shell.execute_reply.started":"2024-03-24T13:16:51.533969Z"},"trusted":true},"outputs":[],"source":["# The dimensions for resizing the images were standardized to 224 by 224 pixels, a common resolution for convolutional neural network (CNN)\n","# inputs due to its balance between detail retention and computational efficiency. This size standardization ensures that the input layer of the CNN receives uniformly sized images, which is critical for the learning process.\n","IMG_SIZE = (224, 224)\n","\n","train_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n","                                                                 image_size=IMG_SIZE,\n","                                                                 label_mode=\"binary\",\n","                                                                 batch_size=32)\n","\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n","                                                                 image_size=IMG_SIZE,\n","                                                                 label_mode=\"binary\",\n","                                                                 batch_size=32,\n","                                                                shuffle=False)\n","\n","val_data = tf.keras.preprocessing.image_dataset_from_directory(directory=val_dir,\n","                                                                 image_size=IMG_SIZE,\n","                                                                 label_mode=\"binary\",\n","                                                                 batch_size=32,\n","                                                                shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory Data Analysis\n","\n","Visualization of Class Distribution\n","A crucial step in the exploratory analysis of the dataset involved assessing the distribution of images across different classes. This assessment aimed to identify any imbalance in the dataset that could potentially bias the machine learning model's training and evaluation processes. To facilitate this analysis, a custom Python function, visualize_class_distribution, was developed and employed. This function automates the process of calculating and visualizing the number of images available for each class within the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:52.616391Z","iopub.status.busy":"2024-03-24T13:16:52.615963Z","iopub.status.idle":"2024-03-24T13:16:52.954856Z","shell.execute_reply":"2024-03-24T13:16:52.953585Z","shell.execute_reply.started":"2024-03-24T13:16:52.616351Z"},"trusted":true},"outputs":[],"source":["# Function to visualize class distribution\n","def visualize_class_distribution(data_dir):\n","    labels = os.listdir(data_dir)\n","    num_images_per_class = []\n","\n","    for label in labels:\n","        label_dir = os.path.join(data_dir, label)\n","        num_images_per_class.append(len(os.listdir(label_dir)))\n","\n","    # Plotting class distribution\n","    plt.figure(figsize=(10, 6))\n","    sns.barplot(x=labels, y=num_images_per_class)\n","    plt.title('Class Distribution')\n","    plt.xlabel('Class')\n","    plt.ylabel('Number of Images')\n","    plt.xticks(rotation=45)\n","    plt.show()\n","\n","# Perform class distribution visualization\n","visualize_class_distribution(train_dir)"]},{"cell_type":"markdown","metadata":{},"source":["The visualize_class_distribution function takes a single parameter, data_dir, which specifies the directory path containing the dataset's image classes. Within this directory, each class's images are expected to be stored in separate subdirectories, named according to the class they represent. The function performs the following operations:\n","\n","Class Identification: It identifies the available classes by listing the directories within data_dir. Each directory name is treated as a class label.\n","\n","Image Counting: For each class, the function counts the number of images by listing the files within each class's corresponding subdirectory. This count represents the total number of images available for that class.\n","\n","Data Visualization: Using Matplotlib and Seaborn libraries, the function then creates a bar plot to visualize the class distribution. The x-axis of the plot represents the class labels, while the y-axis indicates the number of images per class. Additional plot settings, such as figure size, title, axis labels, and x-axis tick rotation, are applied to enhance readability and presentation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:52.956929Z","iopub.status.busy":"2024-03-24T13:16:52.956517Z","iopub.status.idle":"2024-03-24T13:16:54.995881Z","shell.execute_reply":"2024-03-24T13:16:54.994085Z","shell.execute_reply.started":"2024-03-24T13:16:52.956894Z"},"trusted":true},"outputs":[],"source":["#fig = px.pie(\n","#    names=info.Label.unique(),\n","#    values=info.Label.value_counts(),\n","#    hole=0.2,\n","#    width=500,\n","#    height=500\n","#)\n","#fig.update_layout({'title':{'text':'Class Distribution','x':0.45}})\n","#fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:54.998573Z","iopub.status.busy":"2024-03-24T13:16:54.998047Z","iopub.status.idle":"2024-03-24T13:16:56.373226Z","shell.execute_reply":"2024-03-24T13:16:56.371234Z","shell.execute_reply.started":"2024-03-24T13:16:54.998524Z"},"trusted":true},"outputs":[],"source":["# Function to display additional sample images\n","def display_additional_samples(data_dir, num_samples=5):\n","    labels = os.listdir(data_dir)\n","\n","    plt.figure(figsize=(15, 10))\n","    for i, label in enumerate(labels):\n","        label_dir = os.path.join(data_dir, label)\n","        images = os.listdir(label_dir)[:num_samples]\n","        for j, image in enumerate(images):\n","            plt.subplot(len(labels), num_samples, i * num_samples + j + 1)\n","            img = plt.imread(os.path.join(label_dir, image))\n","            plt.imshow(img)\n","            plt.title(label)\n","            plt.axis('off')\n","    plt.show()\n","\n","# Display additional sample images\n","display_additional_samples(train_dir)"]},{"cell_type":"markdown","metadata":{},"source":["**Methodology for Sample Visualization**\n","to enhance the understanding of the dataset's characteristics and ensure a comprehensive exploratory data analysis, a Python function, display_additional_samples, was developed and implemented. This function is designed to systematically display a specified number of sample images from each class present in the dataset. Such visualization aids in assessing the variability within and between classes, crucial for informing subsequent data preprocessing and model training strategies."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:56.375322Z","iopub.status.busy":"2024-03-24T13:16:56.374899Z","iopub.status.idle":"2024-03-24T13:16:56.384634Z","shell.execute_reply":"2024-03-24T13:16:56.383059Z","shell.execute_reply.started":"2024-03-24T13:16:56.375286Z"},"trusted":true},"outputs":[],"source":["# Visualizing data\n","def visualize_random_images(dataset_type=\"train\", label_type=\"Others\"):\n","    \n","    sample = 9\n","    \n","    plt.figure(figsize=(15, 8))\n","    type_dir = train_dir if dataset_type==\"train\" else test_dir\n","    base_dir = os.path.join(type_dir, label_type)\n","    images = random.sample(os.listdir(base_dir), 9)\n","    \n","    for i, image in enumerate(images):\n","        plt.subplot(3, 3, i+1)\n","        img = plt.imread(os.path.join(base_dir, image))\n","        plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:56.388956Z","iopub.status.busy":"2024-03-24T13:16:56.387985Z","iopub.status.idle":"2024-03-24T13:16:58.238583Z","shell.execute_reply":"2024-03-24T13:16:58.237098Z","shell.execute_reply.started":"2024-03-24T13:16:56.388914Z"},"trusted":true},"outputs":[],"source":["visualize_random_images(\"train\", \"Monkeypox\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:58.243881Z","iopub.status.busy":"2024-03-24T13:16:58.243247Z","iopub.status.idle":"2024-03-24T13:16:58.255723Z","shell.execute_reply":"2024-03-24T13:16:58.254155Z","shell.execute_reply.started":"2024-03-24T13:16:58.243845Z"},"trusted":true},"outputs":[],"source":["def plot_loss_curves(history):\n","  \"\"\"\n","  Returns separate loss curves for training and validation metrics.\n","  Args:\n","    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n","  \"\"\" \n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  accuracy = history.history['accuracy']\n","  val_accuracy = history.history['val_accuracy']\n","\n","  epochs = range(len(history.history['loss']))\n","\n","  # Plot loss\n","  plt.plot(epochs, loss, label='training_loss')\n","  plt.plot(epochs, val_loss, label='val_loss')\n","  plt.title('Loss')\n","  plt.xlabel('Epochs')\n","  plt.legend()\n","\n","  # Plot accuracy\n","  plt.figure()\n","  plt.plot(epochs, accuracy, label='training_accuracy')\n","  plt.plot(epochs, val_accuracy, label='val_accuracy')\n","  plt.title('Accuracy')\n","  plt.xlabel('Epochs')\n","  plt.legend();"]},{"cell_type":"markdown","metadata":{},"source":["# Function Implementation\n","The plot_loss_curves function leverages the TensorFlow model's History object, which records performance metrics at successive epochs during the model's training process. The History object encapsulates detailed logs of loss and accuracy metrics, facilitating a comprehensive analysis of the model's training journey. The visualization process is delineated as follows:\n","\n","Metric Extraction: The function extracts the history of loss (loss, val_loss) and accuracy (accuracy, val_accuracy) metrics from the provided History object. These metrics represent the model's performance on the training and validation datasets across all epochs.\n","\n","Epoch Enumeration: The epochs during which the model was trained are enumerated, providing a temporal axis for the performance plots.\n","\n","Loss Visualization: A plot is generated to visualize the training and validation loss over epochs. This plot elucidates the model's optimization trajectory, highlighting how closely the model learns to predict the training data while generalizing to unseen validation data.\n","\n","Accuracy Visualization: In a separate plot, training and validation accuracy metrics are visualized over epochs. This plot showcases the model's improving prediction capabilities as training progresses, offering insights into the model's efficacy in correctly classifying the data.\n","\n","The dual plots of loss and accuracy serve as fundamental indicators of the model's training and validation performance, enabling the identification of key training phases such as rapid learning, plateauing of performance, or the onset of overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:16:58.259199Z","iopub.status.busy":"2024-03-24T13:16:58.258285Z","iopub.status.idle":"2024-03-24T13:17:02.332095Z","shell.execute_reply":"2024-03-24T13:17:02.330816Z","shell.execute_reply.started":"2024-03-24T13:16:58.259163Z"},"trusted":true},"outputs":[],"source":["#The EfficientNetB3 model is initialized with the include_top=False parameter to exclude the original top layers (i.e., the fully connected layers) intended for classification. This exclusion allows for the adaptation of the model to our specific task requirements. \n","base_model = tf.keras.applications.EfficientNetB3(include_top=False)\n","base_model.trainable = True\n","\n","for layer in base_model.layers[:-5]:\n","  layer.trainable = False\n","\n","#Input Layer: An input layer is defined to accommodate images of shape 224x224 pixels with 3 color channels, matching the input dimensions expected by EfficientNetB3.\n","inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n","base_layer = base_model(inputs)\n","#Dropout Layer 1: A dropout layer with a rate of 0.5 follows, introduced to mitigate overfitting by randomly omitting a portion of feature detectors during training.\n","dropout_layer_1 = layers.Dropout(0.5)(base_layer)\n","#Flattening Layer: The feature maps are then flattened, transforming the 2D feature maps into a 1D vector suitable for the dense layers.\n","flat_layer = layers.Flatten()(dropout_layer_1)\n","#Dense Layer 1: A dense layer with 256 neurons and ReLU activation function is employed to learn high-level patterns from the flat feature vector.\n","dense_1 = layers.Dense(256, activation=\"relu\")(flat_layer)\n","#Dropout Layer 2: Another dropout layer with a rate of 0.5 is applied after the first dense layer to further prevent overfitting.\n","dropout_layer_2 = layers.Dropout(0.5)(dense_1)\n","#Dense Layer 2: Subsequently, a second dense layer with 128 neurons and ReLU activation follows, aimed at refining the learned representations.\n","dense_2 = layers.Dense(128, activation=\"relu\")(dropout_layer_2)\n","#Output Layer: The final layer is a dense layer with a single neuron and a sigmoid activation function, designed to output the probability of the image belonging to the target class.\n","outputs = layers.Dense(1, activation=\"sigmoid\")(dense_2)\n","model = Model(inputs, outputs)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Architecture\n","Incorporation of EfficientNetB3 as a Base Model\n","To harness the advantages of pre-trained models for our image classification task, the study employs the EfficientNetB3 architecture, sourced from TensorFlow's Keras applications module. EfficientNetB3 is renowned for its efficiency and effectiveness in balancing model depth, width, and resolution, making it a prime candidate for serving as the foundational layer of our customized neural network."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T13:17:02.334355Z","iopub.status.busy":"2024-03-24T13:17:02.333913Z","iopub.status.idle":"2024-03-24T14:45:14.062463Z","shell.execute_reply":"2024-03-24T14:45:14.061092Z","shell.execute_reply.started":"2024-03-24T13:17:02.334313Z"},"trusted":true},"outputs":[],"source":["#Optimizer: The Adam optimizer was chosen due to its effectiveness in handling sparse gradients and its adaptability in adjusting the learning rate during training. The initial learning rate was set to 0.001, a value commonly used as a starting point for many types of neural networks.\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","#Model Fitting\n","#Following the model's compilation, it underwent a training process using the training dataset (train_data) with validation performed on a separate dataset (val_data). The training was conducted over 20 epochs, allowing the model to iteratively learn from the training data while its performance was simultaneously evaluated on the validation data to monitor for overfitting.\n","history = model.fit(train_data,\n","                    epochs=20,\n","                    validation_data=val_data)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Training and Optimization\n","Compilation of the Neural Network Model\n","prior to training, the neural network model was compiled with specific configurations to optimize its performance for the binary classification task. The compilation process involved the selection of an optimizer, a loss function, and metrics for evaluating the model's performance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:14.066561Z","iopub.status.busy":"2024-03-24T14:45:14.064223Z","iopub.status.idle":"2024-03-24T14:45:14.876396Z","shell.execute_reply":"2024-03-24T14:45:14.875216Z","shell.execute_reply.started":"2024-03-24T14:45:14.06652Z"},"trusted":true},"outputs":[],"source":["plot_loss_curves(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:14.87829Z","iopub.status.busy":"2024-03-24T14:45:14.877909Z","iopub.status.idle":"2024-03-24T14:45:18.8264Z","shell.execute_reply":"2024-03-24T14:45:18.825614Z","shell.execute_reply.started":"2024-03-24T14:45:14.878258Z"},"trusted":true},"outputs":[],"source":["model.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:18.828218Z","iopub.status.busy":"2024-03-24T14:45:18.827884Z","iopub.status.idle":"2024-03-24T14:45:31.963407Z","shell.execute_reply":"2024-03-24T14:45:31.962083Z","shell.execute_reply.started":"2024-03-24T14:45:18.828189Z"},"trusted":true},"outputs":[],"source":["y_pred = tf.math.round(model.predict(test_data))\n","y_true = []\n","for images, labels in test_data.unbatch():\n","  y_true.append(labels.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:31.974576Z","iopub.status.busy":"2024-03-24T14:45:31.974156Z","iopub.status.idle":"2024-03-24T14:45:31.984198Z","shell.execute_reply":"2024-03-24T14:45:31.983029Z","shell.execute_reply.started":"2024-03-24T14:45:31.974539Z"},"trusted":true},"outputs":[],"source":["accuracy_score(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:31.986762Z","iopub.status.busy":"2024-03-24T14:45:31.985794Z","iopub.status.idle":"2024-03-24T14:45:32.006416Z","shell.execute_reply":"2024-03-24T14:45:32.004808Z","shell.execute_reply.started":"2024-03-24T14:45:31.986693Z"},"trusted":true},"outputs":[],"source":["print(classification_report(y_true, y_pred, target_names=train_data.class_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.008449Z","iopub.status.busy":"2024-03-24T14:45:32.007704Z","iopub.status.idle":"2024-03-24T14:45:32.353251Z","shell.execute_reply":"2024-03-24T14:45:32.351835Z","shell.execute_reply.started":"2024-03-24T14:45:32.008415Z"},"trusted":true},"outputs":[],"source":["cm = confusion_matrix(y_true, y_pred)\n","sns.heatmap(cm.astype(\"int\"), annot=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.356688Z","iopub.status.busy":"2024-03-24T14:45:32.356253Z","iopub.status.idle":"2024-03-24T14:45:32.363315Z","shell.execute_reply":"2024-03-24T14:45:32.362007Z","shell.execute_reply.started":"2024-03-24T14:45:32.356655Z"},"trusted":true},"outputs":[],"source":["# สร้างแบบจำลองใหม่โดยใช้ ResNet50\n","#base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n","#base_model.trainable = True  # ทำให้ทุกชั้นของ ResNet50 สามารถฝึกได้\n","\n","# สร้างสถาปัตยกรรมของแบบจำลอง\n","#inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n","#x = base_model(inputs, training=True)\n","#x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n","#x = layers.Dense(256, activation=\"relu\")(x)\n","#x = layers.Dropout(0.5)(x)\n","#outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","#model_resnet50 = Model(inputs, outputs)\n","\n","# คอมไพล์แบบจำลอง\n","#model_resnet50.compile(optimizer=tf.keras.optimizers.Adam(),\n","#                      loss='binary_crossentropy',\n","#                       metrics=['accuracy'])\n","\n","# ฝึกแบบจำลอง\n","#history_resnet50 = model_resnet50.fit(train_data,\n","#                                      epochs=20,\n","#                                      validation_data=val_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.366686Z","iopub.status.busy":"2024-03-24T14:45:32.365324Z","iopub.status.idle":"2024-03-24T14:45:32.378559Z","shell.execute_reply":"2024-03-24T14:45:32.377655Z","shell.execute_reply.started":"2024-03-24T14:45:32.366635Z"},"trusted":true},"outputs":[],"source":["#def plot_loss_curves(history):\n","#    \"\"\"\n","#    Returns separate loss curves for training and validation metrics.\n","#    \"\"\"\n","#    loss = history.history['loss']\n","#    val_loss = history.history['val_loss']\n","\n","#    accuracy = history.history['accuracy']\n","#    val_accuracy = history.history['val_accuracy']\n","\n","#    epochs = range(len(history.history['loss']))\n","\n","    # Plot loss\n","#    plt.figure(figsize=(8, 8))\n","#    plt.plot(epochs, loss, label='Training Loss')\n","#    plt.plot(epochs, val_loss, label='Validation Loss')\n","#    plt.title('Training and Validation Loss')\n","#    plt.xlabel('Epochs')\n","#    plt.legend()\n","\n","    # Plot accuracy\n","#    plt.figure(figsize=(8, 8))\n","#    plt.plot(epochs, accuracy, label='Training Accuracy')\n","#    plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n","#    plt.title('Training and Validation Accuracy')\n","#    plt.xlabel('Epochs')\n","#    plt.legend()\n","\n","#plot_loss_curves(history_resnet50)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.381225Z","iopub.status.busy":"2024-03-24T14:45:32.38047Z","iopub.status.idle":"2024-03-24T14:45:32.39626Z","shell.execute_reply":"2024-03-24T14:45:32.394847Z","shell.execute_reply.started":"2024-03-24T14:45:32.381184Z"},"trusted":true},"outputs":[],"source":["# ประเมินโมเดลบนชุดข้อมูลทดสอบ\n","#test_loss, test_accuracy = model_resnet50.evaluate(test_data)\n","#print(f\"Test Loss: {test_loss}\")\n","#print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.399094Z","iopub.status.busy":"2024-03-24T14:45:32.398399Z","iopub.status.idle":"2024-03-24T14:45:32.407446Z","shell.execute_reply":"2024-03-24T14:45:32.406043Z","shell.execute_reply.started":"2024-03-24T14:45:32.399038Z"},"trusted":true},"outputs":[],"source":["# ทำนายชุดข้อมูลทดสอบ\n","#y_pred = model_resnet50.predict(test_data)\n","#y_pred = tf.math.round(y_pred)  # ปรับให้เป็น 0 หรือ 1\n","\n","# รวบรวม labels จริงจากชุดข้อมูลทดสอบ\n","#y_true = np.concatenate([labels for _, labels in test_data], axis=0)\n","\n","# คำนวณความแม่นยำ\n","#accuracy = accuracy_score(y_true, y_pred)\n","#print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.409588Z","iopub.status.busy":"2024-03-24T14:45:32.408942Z","iopub.status.idle":"2024-03-24T14:45:32.417908Z","shell.execute_reply":"2024-03-24T14:45:32.416441Z","shell.execute_reply.started":"2024-03-24T14:45:32.409553Z"},"trusted":true},"outputs":[],"source":["# สร้างและแสดง confusion matrix\n","#cm = confusion_matrix(y_true, y_pred)\n","#plt.figure(figsize=(10, 7))\n","#sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n","#plt.xlabel('Predicted')\n","#plt.ylabel('True')\n","#plt.title('Confusion Matrix')"]},{"cell_type":"markdown","metadata":{},"source":["# Other modules for performance comparison testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.420336Z","iopub.status.busy":"2024-03-24T14:45:32.419884Z","iopub.status.idle":"2024-03-24T14:45:32.833397Z","shell.execute_reply":"2024-03-24T14:45:32.83192Z","shell.execute_reply.started":"2024-03-24T14:45:32.420301Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras import layers, models\n","\n","# สร้างสถาปัตยกรรมของแบบจำลอง\n","inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n","\n","# Convolutional layer ชั้นที่ 1\n","x = layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(inputs)\n","x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","\n","# Convolutional layer ชั้นที่ 2\n","x = layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(x)\n","\n","# Add a fully connected layer with 256 hidden units and ReLU activation\n","x = layers.Dense(256, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)  # Add a dropout rate of 0.5\n","\n","# Add a final sigmoid layer for classification\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","# Create the model\n","model_custom = models.Model(inputs, outputs)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Architecture\n","To address the specific requirements of our binary classification task, a custom convolutional neural network (CNN) model was designed and implemented. The architecture of this model was constructed to effectively extract and learn features from images, facilitating accurate classification. The model architecture comprises several layers, each serving a distinct purpose in the feature extraction and classification process:\n","\n","**Input Layer**: The model begins with an input layer designed to receive images of shape 224x224 pixels with 3 color channels. This standardization is crucial for processing images in a uniform manner.\n","\n","**First Convolutional Layer**: The initial layer of convolution employs 32 filters with a kernel size of 3x3, followed by a ReLU activation function. This layer is aimed at capturing basic patterns such as edges and colors. A subsequent max pooling layer with a pool size of 2x2 reduces the dimensionality, focusing on the most prominent features.\n","\n","**Second Convolutional Layer**: A second convolutional layer, consisting of 64 filters and a 3x3 kernel, further processes the feature maps from the previous layer. This is again followed by max pooling, enhancing the model's ability to identify more complex features in the images.\n","\n","**Flattening Layer**: The feature maps are flattened into a one-dimensional vector, preparing the data for the fully connected layers.\n","\n","**Fully Connected Layer**: A dense layer with 256 neurons and ReLU activation function is employed to learn high-level patterns from the flattened feature maps. A dropout layer with a rate of 0.5 is incorporated to reduce the risk of overfitting by randomly omitting a portion of the neurons during training.\n","\n","**Output Layer**: The final layer is a dense layer with a single neuron and a sigmoid activation function, designed to output the probability that the image belongs to the target class."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:45:32.835317Z","iopub.status.busy":"2024-03-24T14:45:32.834972Z","iopub.status.idle":"2024-03-24T15:32:23.009515Z","shell.execute_reply":"2024-03-24T15:32:23.008163Z","shell.execute_reply.started":"2024-03-24T14:45:32.835286Z"},"trusted":true},"outputs":[],"source":["#Optimizer: The Adam optimizer was employed with a learning rate of 0.001. Adam is renowned for its efficiency in gradient descent optimization by adaptively adjusting the learning rate, making it particularly suited for deep learning models where the landscape of the loss function can be highly complex.\n","#Loss Function: Binary crossentropy was chosen as the loss function. This selection is aligned with the binary nature of our classification task, where the model predicts the likelihood of images belonging to one of two possible classes. Binary crossentropy effectively quantifies the difference between the predicted probabilities and the actual binary labels, guiding the model towards better accuracy.\n","model_custom.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                     loss='binary_crossentropy',\n","                     metrics=['accuracy'])\n","\n","#Model Training\n","#The model was trained over 20 epochs, allowing sufficient iterations for the model to learn from the training data progressively. An epoch in this context refers to one complete pass of the training dataset through the model.\n","history_custom = model_custom.fit(train_data,\n","                                  epochs=20,\n","                                  validation_data=val_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T15:32:23.019575Z","iopub.status.busy":"2024-03-24T15:32:23.019192Z","iopub.status.idle":"2024-03-24T15:32:23.707032Z","shell.execute_reply":"2024-03-24T15:32:23.705834Z","shell.execute_reply.started":"2024-03-24T15:32:23.019545Z"},"trusted":true},"outputs":[],"source":["def plot_loss_curves(history):\n","    \"\"\"\n","    Returns separate loss curves for training and validation metrics.\n","    \"\"\"\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    \n","    accuracy = history.history['accuracy']\n","    val_accuracy = history.history['val_accuracy']\n","    \n","    epochs = range(len(history.history['loss']))\n","    \n","    # Plot loss\n","    plt.figure(figsize=(8, 8))\n","    plt.plot(epochs, loss, label='Training Loss')\n","    plt.plot(epochs, val_loss, label='Validation Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","    \n","    # Plot accuracy\n","    plt.figure(figsize=(8, 8))\n","    plt.plot(epochs, accuracy, label='Training Accuracy')\n","    plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n","    plt.title('Training and Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","\n","plot_loss_curves(history_custom)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation of Model Training Dynamics\n","Visual Analysis of Training and Validation Metrics\n","To comprehensively assess the performance of the custom convolutional neural network model throughout its training phase, a visualization function, plot_loss_curves, was developed and applied. This function is instrumental in depicting the model's learning progression, facilitating the identification of key training characteristics such as convergence behavior, overfitting, or underfitting.\n","\n","**Function Overview**\n","The plot_loss_curves function extracts the training and validation loss and accuracy metrics from the model's training history, provided by TensorFlow's History object. It then generates two separate plots:\n","\n","**Training and Validation Loss**: The first plot visualizes the loss metrics, with the training loss depicted alongside the validation loss over the course of training epochs. This plot is crucial for observing how the model's performance improves and whether it begins to overfit to the training data by exhibiting an increasing trend in validation loss.\n","\n","**Training and Validation Accuracy**: The second plot displays the accuracy metrics, plotting both training and validation accuracy. This visualization offers insights into the model's capability to correctly classify the images, highlighting the progression of accuracy and its stabilization or potential divergence, indicative of overfitting or underfitting, respectively.\n","\n","**Visualization Process**\n","Upon invocation, plot_loss_curves executes the following steps:\n","\n","**Metric Extraction**: The function retrieves the loss and accuracy metrics from the History object's history attribute, encompassing both training and validation phases.\n","\n","**Epoch Enumeration**: It enumerates the epochs based on the length of the loss history, providing a temporal axis for the plots.\n","\n","**Plot Configuration**: For each metric (loss and accuracy), a separate plot is configured, setting the figure size to 8x8 inches for clarity. The training and validation metrics are plotted as distinct lines, with appropriate labels and legends for differentiation.\n","\n","**Display**: The plots are titled 'Training and Validation Loss' and 'Training and Validation Accuracy' respectively, with epochs on the x-axis and the metric values on the y-axis. Legends distinguish between training and validation lines, aiding in interpretation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T15:32:23.709699Z","iopub.status.busy":"2024-03-24T15:32:23.708443Z","iopub.status.idle":"2024-03-24T15:32:24.399491Z","shell.execute_reply":"2024-03-24T15:32:24.397773Z","shell.execute_reply.started":"2024-03-24T15:32:23.709654Z"},"trusted":true},"outputs":[],"source":["# ประเมินโมเดลบนชุดข้อมูลทดสอบ\n","test_loss, test_accuracy = model_custom.evaluate(test_data)\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T15:32:24.40677Z","iopub.status.busy":"2024-03-24T15:32:24.406322Z","iopub.status.idle":"2024-03-24T15:32:26.273367Z","shell.execute_reply":"2024-03-24T15:32:26.272178Z","shell.execute_reply.started":"2024-03-24T15:32:24.4067Z"},"trusted":true},"outputs":[],"source":["# ทำนายชุดข้อมูลทดสอบและปรับค่าเป็น 0 หรือ 1\n","y_pred = model_custom.predict(test_data)\n","y_pred_rounded = tf.round(y_pred)\n","\n","# รวบรวม labels จริงจากชุดข้อมูลทดสอบ\n","y_true = np.concatenate([y for x, y in test_data], axis=0)\n","\n","# คำนวณความแม่นยำ\n","accuracy = accuracy_score(y_true, y_pred_rounded)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# สร้างและแสดง confusion matrix\n","cm = confusion_matrix(y_true, y_pred_rounded)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion\n","\n","This project has attempted to apply deep learning technology to create models for classification and detection of monkeypox skin lesions using the \"Monkeypox Skin Lesion Dataset\" from Kaggle. General Convolutional Neural Network (CNN) and EfficientNetB3 were employed to compare the performance of both models in image classification. The results revealed that due to the nature of this image dataset requiring high accuracy in classification, the more complex and suitable model, EfficientNetB3, provided higher accuracy (approximately 89%). Although the standard CNN model could process data faster, it yielded lower accuracy (approximately 60%) for tasks demanding high precision. However, each model is inherently suitable for specific types of datasets, depending on the complexity of the data and the desired outcomes from that dataset."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2308447,"sourceId":3907076,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":4}
